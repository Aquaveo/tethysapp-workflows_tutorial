# Filename: Run_Job_Step.dag.condor.sub
# Generated by condor_submit_dag Run_Job_Step.dag 
universe    = scheduler
executable  = /usr/bin/condor_dagman
getenv      = CONDOR_CONFIG,_CONDOR_*,PATH,PYTHONPATH,PERL*,PEGASUS_*,TZ,HOME,USER,LANG,LC_ALL,BEARER_TOKEN,BEARER_TOKEN_FILE,XDG_RUNTIME_DIR
output      = Run_Job_Step.dag.lib.out
error       = Run_Job_Step.dag.lib.err
log         = Run_Job_Step.dag.dagman.log
remove_kill_sig = SIGUSR1
My.OtherJobRemoveRequirements = "DAGManJobId =?= $(cluster)"
# Note: default on_exit_remove expression:
# (ExitSignal =?= 11 || (ExitCode =!= UNDEFINED && ExitCode >=0 && ExitCode <= 2))
# attempts to ensure that DAGMan is automatically
# requeued by the schedd if it exits abnormally or
# is killed (e.g., during a reboot).
on_exit_remove = (ExitSignal =?= 11 || (ExitCode =!= UNDEFINED && ExitCode >=0 && ExitCode <= 2))
copy_to_spool = False
arguments = "-p 0 -f -l . -Lockfile Run_Job_Step.dag.lock -Dag Run_Job_Step.dag -MaxIdle 1000 -CsdVersion $CondorVersion:' '23.10.18' '2024-11-18' 'BuildID:' '769621' 'PackageID:' '23.10.18-1+ubu22' 'GitSHA:' '0208a1f0' '$ -dagman /usr/bin/condor_dagman -AutoRescue 1 -DoRescueFrom 0"
environment = "_CONDOR_DAGMAN_LOG=Run_Job_Step.dag.dagman.out _CONDOR_MAX_DAGMAN_LOG=0 _CONDOR_SCHEDD_ADDRESS_FILE=/var/spool/condor/.schedd_address _CONDOR_SCHEDD_DAEMON_AD_FILE=/var/spool/condor/.schedd_classad"
queue
